{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The given dataset was imported and processed through various stages\n",
    "* The project was structured to be appear less hacky and more like something that could sustain some evolution and eventual deployment.\n",
    "* Data processing can be done through the command line to update files and rerun the processing of the data.\n",
    "* Features were explored and their impact on the target variable explained where it was evident\n",
    "* Feature engineering was performed on the categorical features and a reduction in feature number was also carried out. \n",
    "* Features were scaled before fitting the classifiers, this, although not shown, but improved the results before using scaling. \n",
    "* Several classifiers were fit to the data and their performance measured not only in accuracy, but using the AUC and confusion matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difficulties and critique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A few features were encountered that were categorical in nature, but numeric in values. This seemed to throw off earlier attempts to fit data and scale. In the end these were discarded, since alternative features with text values were also present in the dataset.\n",
    "* The class imbalance represented a challenge, since accuracy is no longer a true measure of performance, then the ROC curve, confusion matrix and AUC were used to estimate the goodness of fit for the classifiers.\n",
    "* There are many (MANY!) classifiers available and an in depth exploration would have taken considerably longer than the few hours available. It remains as future work to explore the different options, like making use of the class_weight parameter available for several of the classifiers.\n",
    "* The feature selection part is non trivial, since once the categorical attributes were converted to one-hot, it generated around 170 features in total, despite the initial grouping performed on the data.\n",
    "* The grouping itself is sensible, yet not bulletproof, since the values in the features were grouped using the analyst's own knowledge, therefore some bias might be present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several features show relevant variance and indication of higher earnings:\n",
    "  * age\n",
    "  * weeks worked in year\n",
    "  * major occupation code_not well-paid occ\n",
    "  * dividends from stocks\n",
    "  * num persons worked for employer\n",
    "  * major occupation code_well-paid occ\n",
    "  * tax filer stat_Joint both under 65\n",
    "  * education_no-college\n",
    "  * capital gains\n",
    "  * family members under 18_Unknown\n",
    "  * education_college\n",
    "  * detailed household summary in household_Not householder\n",
    "  * sex_Male\n",
    "  \n",
    "Other features, that initially were thought to have contributed more heavily, like race, proved to not be nearly as important. Hence the benefit of automatic feature selection, rather than relying on the analyst's opinions or beliefs \n",
    "\n",
    "If the data sample is representative of the population as a whole, then it also shows that 50K USD is quite a high salary as is not so common. \n",
    "\n",
    "Of course other factors not available here could be interesting to explore, for example it is not mentioned where the person lives or the cost of living in the area. This might point to a purchasing power, rather than pure salary, which might be more interesting to decision makers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dataiku]",
   "language": "python",
   "name": "conda-env-dataiku-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
